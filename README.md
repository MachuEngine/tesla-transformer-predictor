# 테슬라 주가 예측 모델 결과 분석

---

## 1. 개요
이번 프로젝트는 Transformer 기반의 딥러닝 모델로 Tesla 주가를 예측하는 것을 목표로 진행되었습니다.  
모델은 과거 50일치 주가 데이터를 입력받아 하루 뒤 주가를 예측하도록 학습되었으며, 이 예측 과정을 600일간 반복(Rollout)하여 미래 주가를 예측했습니다.  
아래에서는 데이터 준비부터 모델 학습 과정, 최종 예측 결과에 대한 분석 내용과 한계점, 개선 방안을 다룹니다.

---

## 2. 데이터 구성 및 전처리

### 2.1 데이터 수집
- **데이터 출처**: `yfinance` 라이브러리를 사용해 2015년 1월 1일부터 2025년 2월 5일까지의 Tesla 주가 데이터를 다운로드
- **사용 피처**: 
  - 종가(Close), 거래량(Volume), 시가(Open), 고가(High), 저가(Low) 총 5개 피처를 입력으로 활용

### 2.2 정규화 및 분할
- **정규화**: MinMaxScaler를 적용해 모든 피처를 \[0, 1\] 범위로 변환
- **데이터 분할**: 전체 데이터의 80%를 학습용, 20%를 테스트용으로 분할

---

## 3. 모델 구조 및 학습 방법

### 3.1 모델 구조
- Transformer 기반 모델
  - **입력**: 5차원 데이터를 `d_model=252` 차원으로 임베딩
  - **구성**: 인코더와 디코더 블록 각각 3층(`num_layers=3`), `nhead=4`, 드롭아웃(dropout) 0.1 적용
  - **출력**: 5차원(종가, 거래량 등 피처 유지)

### 3.2 학습 전략
- **손실 함수**: MSELoss(회귀 문제용)
- **최적화**: Adam(학습률 0.001에서 시작)
- **학습률 스케줄러**: StepLR을 사용해 20에폭마다 학습률을 절반으로 감소
- **학습 에폭**: 총 100 에폭 진행

### 3.3 예측 과정 (Rollout)
- 학습: “과거 50일 → 다음 1일”을 예측하도록 모델 학습
- 테스트: 
  - 초기 50일 데이터를 입력하여 1일 예측
  - 예측값을 입력에 추가하고 가장 오래된 데이터를 제거하며 반복, 600일 미래를 예측

---

## 4. 결과 분석

### 4.1 학습 손실 추이
- 초기 손실이 0.278에서 시작해, 학습이 진행됨에 따라 빠르게 0.01 이하로 감소
- 학습률 감소 시점마다 손실이 완만하게 하락, 최종적으로 약 0.0018까지 도달

### 4.2 예측 그래프 해석
- **학습 구간**: 실제 주가 패턴을 거의 그대로 따라갈 만큼 학습 데이터에 적합
- **미래 예측 구간**: 
  - 실제 주가가 급등(450달러 부근)하는 구간에서 모델은 이를 따라가지 못하고 완만하게 상승 후 고착되는 형태를 보임
  - 이는 **오차 누적**과 **변동성 부족 반영** 문제로 추정

```
Epoch 1/100, Loss: 0.278031, LR: 0.001000
Epoch 2/100, Loss: 0.023695, LR: 0.001000
Epoch 3/100, Loss: 0.019582, LR: 0.001000
Epoch 4/100, Loss: 0.014596, LR: 0.001000
Epoch 5/100, Loss: 0.011531, LR: 0.001000
Epoch 6/100, Loss: 0.007390, LR: 0.001000
Epoch 7/100, Loss: 0.007102, LR: 0.001000
Epoch 8/100, Loss: 0.005705, LR: 0.001000
Epoch 9/100, Loss: 0.004671, LR: 0.001000
...
Epoch 90/100, Loss: 0.001837, LR: 0.000063
Epoch 91/100, Loss: 0.001814, LR: 0.000063
Epoch 92/100, Loss: 0.001789, LR: 0.000063
Epoch 93/100, Loss: 0.001852, LR: 0.000063
Epoch 94/100, Loss: 0.001808, LR: 0.000063
Epoch 95/100, Loss: 0.001801, LR: 0.000063
Epoch 96/100, Loss: 0.001796, LR: 0.000063
Epoch 97/100, Loss: 0.001843, LR: 0.000063
Epoch 98/100, Loss: 0.001839, LR: 0.000063
Epoch 99/100, Loss: 0.001815, LR: 0.000063
Epoch 100/100, Loss: 0.001800, LR: 0.000031
```

![image](https://github.com/user-attachments/assets/0916e0be-3d24-4e31-af9c-b7086a0a0469)

---

## 5. 한계점

1. **단일 스텝 예측 + Rollout의 한계**
   - 하루 뒤만 학습한 뒤 이를 600번 반복하다 보니, 예측 오차가 누적되며 장기 예측에서 실제 변동성을 따라가지 못함

2. **시장 외적 요인 미반영**
   - 테슬라 주가는 기업 이벤트, 거시경제 이슈 등 외부 요인에 크게 영향을 받음
   - 본 모델은 단순 주가 데이터만 사용했기 때문에 이러한 요인을 반영하지 못함

3. **과적합**
   - 학습 데이터에서는 손실이 매우 낮았으나, 테스트 구간에서 예측 성능 저하 발생

---

## 6. 개선 방안

1. **멀티스텝 예측 학습**
   - “과거 50일 → 향후 N일(예: 10일, 30일 등) 동시 예측” 방식으로 학습해 장기 예측 성능을 강화

2. **디코더 입력 개선**
   - 예측 시 디코더에 매번 0벡터 대신 이전 예측값을 활용하는 Teacher Forcing 기법 적용

3. **추가 피처 및 도메인 지식 반영**
   - 거시경제 지표(금리, 환율 등), 기술적 지표(RSI, MACD 등)를 추가해 모델의 정보량을 확대

4. **하이퍼파라미터 및 구조 조정**
   - Transformer 블록 수, 헤드 수(nhead), 드롭아웃 비율 등을 다양하게 실험하거나, LSTM/GRU 등 다른 모델과 비교

5. **규제(Regularization) 강화**
   - Dropout을 늘리거나 Weight Decay를 활용해 과적합 완화

---

## 7. 결론
Transformer 모델은 학습 구간에서 매우 낮은 손실(MSE)을 기록했으나, 장기 예측에서는 실제 주가의 급격한 변동을 따라가지 못했습니다.  
이는 장기 예측 시 오차가 누적되는 구조적 문제와 변동성이 큰 종목의 특성에서 기인합니다.  

멀티스텝 예측, 디코더 입력 개선, 추가 지표 활용 등 다양한 접근을 통해 모델의 예측 성능을 개선할 수 있을 것으로 보입니다.  
또한, 여러 시계열 모델을 교차 비교함으로써 Transformer 기반 모델의 한계를 보완할 수 있을 것으로 기대됩니다.

---

## 부록: 모델 및 하이퍼파라미터 요약
- **모델**: Transformer (인코더·디코더 3층, nhead=4, d_model=252)
- **시퀀스 길이**: 50  
- **피처 수**: 5 (종가, 거래량, 시가, 고가, 저가)
- **학습률**: 초기 0.001 → 20에폭마다 0.5배 감소(StepLR)
- **배치 크기**: 32  
- **학습 에폭**: 100  
- **손실 함수**: MSELoss  
- **데이터 분할**: 80%(학습), 20%(테스트)
